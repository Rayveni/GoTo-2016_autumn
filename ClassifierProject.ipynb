{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модули\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GT 540M (CNMeM is disabled, cuDNN not available)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эта функция очищает data frame от спикеров, которые говорили очень мало и мусорных кандидатов\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_df(df, x = 1, y = 15): \n",
    "    ind = df.Speaker.value_counts()[x:y].index \n",
    "    return df[(df.Speaker.isin(ind) ) & (~ df.Speaker.isin(['CANDIDATES','OTHER']))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка данных\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем датасет и очищаем его"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Text</th>\n",
       "      <th>Date</th>\n",
       "      <th>Party</th>\n",
       "      <th>Location</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>Thank you.</td>\n",
       "      <td>2/11/16</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>Milwaukee, Wisconsin</td>\n",
       "      <td>http://www.presidency.ucsb.edu/ws/index.php?pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Sanders</td>\n",
       "      <td>Well, Gwen and Judy, thank you very much for h...</td>\n",
       "      <td>2/11/16</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>Milwaukee, Wisconsin</td>\n",
       "      <td>http://www.presidency.ucsb.edu/ws/index.php?pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>I'm running for president to knock down all th...</td>\n",
       "      <td>2/11/16</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>Milwaukee, Wisconsin</td>\n",
       "      <td>http://www.presidency.ucsb.edu/ws/index.php?pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Sanders</td>\n",
       "      <td>Well, to put that in a context, Judy, I think ...</td>\n",
       "      <td>2/11/16</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>Milwaukee, Wisconsin</td>\n",
       "      <td>http://www.presidency.ucsb.edu/ws/index.php?pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Sanders</td>\n",
       "      <td>... Of course there will be a limit, but when ...</td>\n",
       "      <td>2/11/16</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>Milwaukee, Wisconsin</td>\n",
       "      <td>http://www.presidency.ucsb.edu/ws/index.php?pi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Line  Speaker                                               Text     Date  \\\n",
       "6      7  Clinton                                         Thank you.  2/11/16   \n",
       "10    11  Sanders  Well, Gwen and Judy, thank you very much for h...  2/11/16   \n",
       "14    15  Clinton  I'm running for president to knock down all th...  2/11/16   \n",
       "20    21  Sanders  Well, to put that in a context, Judy, I think ...  2/11/16   \n",
       "22    23  Sanders  ... Of course there will be a limit, but when ...  2/11/16   \n",
       "\n",
       "         Party              Location  \\\n",
       "6   Democratic  Milwaukee, Wisconsin   \n",
       "10  Democratic  Milwaukee, Wisconsin   \n",
       "14  Democratic  Milwaukee, Wisconsin   \n",
       "20  Democratic  Milwaukee, Wisconsin   \n",
       "22  Democratic  Milwaukee, Wisconsin   \n",
       "\n",
       "                                                  URL  \n",
       "6   http://www.presidency.ucsb.edu/ws/index.php?pi...  \n",
       "10  http://www.presidency.ucsb.edu/ws/index.php?pi...  \n",
       "14  http://www.presidency.ucsb.edu/ws/index.php?pi...  \n",
       "20  http://www.presidency.ucsb.edu/ws/index.php?pi...  \n",
       "22  http://www.presidency.ucsb.edu/ws/index.php?pi...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('primary_debates_cleaned.csv')\n",
    "data = clean_df(data)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100 # длина вектора, которым мы кодируем слово\n",
    "MAX_SEQ_LEN = 255   # установка формы текста - 255 слов "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5634 texts.\n"
     ]
    }
   ],
   "source": [
    "LE = LabelEncoder()\n",
    "\n",
    "Y_l_encoded = LE.fit_transform(data.Speaker.values) # заменяем каждое название класса на численное значение\n",
    "\n",
    "labels_index = {}\n",
    "\n",
    "for index,text in enumerate(data.Text.values):\n",
    "    \n",
    "    # берем лэйбл для текста, переведенный в число из Y_l_encoded (index текста = index лэйбла)\n",
    "    label_id = Y_l_encoded[index]\n",
    "\n",
    "    labels_index[text] = label_id # добавляем в словарик пару, где ключ - текст, значение - номер лэйбла\n",
    "\n",
    "labels = Y_l_encoded\n",
    "texts = data.Text.values\n",
    "print('Found %s texts.' % len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9578 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(nb_words=10000)  \n",
    "tokenizer.fit_on_texts(texts)     # учим токенайзер\n",
    "sequences = tokenizer.texts_to_sequences(texts) # переводим текст в последовательности\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "# если слов меньше 255 - дополняем 0-ми, в противном случае - обрезаем\n",
    "X = pad_sequences(sequences, maxlen=MAX_SEQ_LEN)  \n",
    "\n",
    "# one hot encoding классов (лэйблов)\n",
    "labels = to_categorical(np.asarray(labels))\n",
    "\n",
    "# разбиваем данные на train и test, перемешав\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "X = X[indices]\n",
    "labels = labels[indices]\n",
    "# задаем часть тестовой выборки - 0.3\n",
    "nb_validation_samples = int(0.3 * X.shape[0])\n",
    "\n",
    "X_train = X[:-nb_validation_samples]\n",
    "Y_train = labels[:-nb_validation_samples]\n",
    "X_test = X[-nb_validation_samples:]\n",
    "Y_test = labels[-nb_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# подключаем словарь embedding-a , в котором каждому имеющемуся там слову сопоставлены 100 численных значений \n",
    "embeddings_index = {}  \n",
    "f = open(os.path.join('/home/egor/projects/GoToSchoolAutumn', 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()  # значения в словаре представлены словом и далее строкой чисел, поэтому сплитим их\n",
    "    word = values[0]       # - ключ\n",
    "    coefs = np.asarray(values[1:], dtype='float32') # 100 циферок\n",
    "    embeddings_index[word] = coefs # тот же словарь , только со структурой ('слово':[зн-е1,зн-е2...зн-е100])\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM)) # делаем веса для embedding-слоя \n",
    "\n",
    "# итереруемся по всем уникальным словам из наших текстов и их индексам, которые сделал токенайзер\n",
    "for word, i in word_index.items(): \n",
    "    embedding_vector = embeddings_index.get(word) # для слова берем те самые 100 значений из словаря\n",
    "    \n",
    "    if embedding_vector is not None:   \n",
    "        # если слова в словаре нет - получаем вектор из 100 нулей\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense,LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "from keras.regularizers import l1l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задаем веса классам т.е вычитаем из единицы долю класса во всех наблюдениях "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "length = float(data.shape[0]) \n",
    "weights = Counter()\n",
    "for cl in Y_l_encoded:\n",
    "    weights[cl] += 1\n",
    "    \n",
    "values = np.array(weights.values())\n",
    "keys = np.array(weights.keys())\n",
    "\n",
    "new_values = 1 - values/length\n",
    "\n",
    "class_weights = dict(zip(keys, new_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.96308129215477456,\n",
       " 1: 0.92545260915867944,\n",
       " 2: 0.94018459353922612,\n",
       " 3: 0.87486687965921195,\n",
       " 4: 0.94675186368477104,\n",
       " 5: 0.91231806886758959,\n",
       " 6: 0.94994675186368482,\n",
       " 7: 0.96024139155129573,\n",
       " 8: 0.91018814341498044,\n",
       " 9: 0.85268015619453319,\n",
       " 10: 0.9250976215832446,\n",
       " 11: 0.8391906283280085}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Архитектура сетки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(len(word_index) + 1, EMBEDDING_DIM, input_length=MAX_SEQ_LEN, weights=[embedding_matrix]))\n",
    "model.add(LSTM(100))\n",
    "\n",
    "model.add(Dense(64, activation='tanh', W_regularizer=l1l2(), b_regularizer=l1l2()))\n",
    "\n",
    "model.add(Dense(12, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.save('model.h5')\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = load_model('model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist1 = model.fit(X_train,Y_train, nb_epoch=50,batch_size=200,class_weight=class_weights,validation_data=[X_test,Y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняем веса, чтобы не обучать заново каждый раз после перезагрузки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.save_weights('goodmodel1_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Смотрим точность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этой функцией \"декодим\" наш класс, т.е из вектора, состоящего из вероятностей принадлежности к каждому классу делаем вектор, определяющий класс\n",
    "\n",
    "[0.066, 0.124, 0.071, 0.101, 0.027, 0.085, 0.064, 0.057, 0.068, 0.099, 0.053, 0.027, 0.128, 0.03] -> [0,0,0,0,0,0,0,0,0,0,0,0,1,0]   (13 класс)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_true_classes(pred):\n",
    "    true_classes = []\n",
    "    for row in pred:\n",
    "        cl = np.zeros(12)\n",
    "        index_of_max = row.argmax()\n",
    "\n",
    "        cl[index_of_max] = 1\n",
    "\n",
    "        true_classes.append(cl)\n",
    "    true_classes = np.array(true_classes)\n",
    "    return true_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, которая считает accuracy для каждого класса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def my_accuracy(y_true,y_pred):\n",
    "    cl_dict = {}\n",
    "    length = y_true.shape[0]\n",
    "      \n",
    "    for i in range(length):\n",
    "        if y_true[i].argmax() not in cl_dict:\n",
    "        \n",
    "            cl_dict[y_true[i].argmax()] = []\n",
    "        \n",
    "        if (y_true[i] == y_pred[i]).all():\n",
    "            cl_dict[y_true[i].argmax()].append(1)\n",
    "        else:\n",
    "            cl_dict[y_true[i].argmax()].append(0)\n",
    "     \n",
    "    result = []\n",
    "   \n",
    "    for key,values in cl_dict.items():\n",
    "        Sum = sum(values)\n",
    "  \n",
    "        accuracy = Sum/float(len(values))  \n",
    "        result.append((key,accuracy))\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для красивого вывода accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_results(Y_true,Y_pred):\n",
    "    results = my_accuracy(Y_true, Y_pred)\n",
    "\n",
    "    return pd.DataFrame({'accuracy':map(lambda x: x[1],results)},\n",
    "                             index=LE.inverse_transform(map(lambda x: x[0],results)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предсказываем вероятности (для train и для test) пренадлежности к классам и затем определяем эти классы для каждого вектора вероятностей. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3944/3944 [==============================] - 17s    \n",
      "1690/1690 [==============================] - 7s     \n"
     ]
    }
   ],
   "source": [
    "model.load_weights('goodmodel1_weights.h5')\n",
    "train_pred = model.predict_proba(X_train)\n",
    "true_pred_train = get_true_classes(train_pred)\n",
    "\n",
    "test_pred = model.predict_proba(X_test)\n",
    "true_pred_test = get_true_classes(test_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность (test) на каждом классе отдельно - отношение количества правильных предсказаний к количеству всех предсказаний для данного класса "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bash</th>\n",
       "      <td>0.391304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blitzer</th>\n",
       "      <td>0.469231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bush</th>\n",
       "      <td>0.597826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clinton</th>\n",
       "      <td>0.748837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cooper</th>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cruz</th>\n",
       "      <td>0.728682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kasich</th>\n",
       "      <td>0.637363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kelly</th>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rubio</th>\n",
       "      <td>0.705128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sanders</th>\n",
       "      <td>0.871681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tapper</th>\n",
       "      <td>0.823077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trump</th>\n",
       "      <td>0.889655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         accuracy\n",
       "Bash     0.391304\n",
       "Blitzer  0.469231\n",
       "Bush     0.597826\n",
       "Clinton  0.748837\n",
       "Cooper   0.714286\n",
       "Cruz     0.728682\n",
       "Kasich   0.637363\n",
       "Kelly    0.647887\n",
       "Rubio    0.705128\n",
       "Sanders  0.871681\n",
       "Tapper   0.823077\n",
       "Trump    0.889655"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_results(Y_test,true_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводим точность на train и на test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.710953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.733136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       accuracy\n",
       "train  0.710953\n",
       "test   0.733136"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'accuracy':[accuracy_score(Y_train,true_pred_train),\n",
    "              accuracy_score(Y_test,true_pred_test)]}, index=['train','test'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
